{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hegame1998/Supermarket-store/blob/main/machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qcQpwJQwQwwl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.cluster import KMeans\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://github.com/hegame1998/Supermarket-store/main/Stores.csv')"
      ],
      "metadata": {
        "id": "khRMCsHgRBMM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "ae6ed5fa-8e30-4c04-dec3-8509ce674fcc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 404: Not Found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2206534117>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msuicide_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://github.com/hegame1998/Supermarket-store/main/Stores.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "vL_H65kFRtZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Yj_8Zg5hRz64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exploratory data analysis"
      ],
      "metadata": {
        "id": "zFAWjpt15o6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values = df.nunique()\n",
        "\n",
        "print(unique_values)\n"
      ],
      "metadata": {
        "id": "oiDMNqm186aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_ids =df['Store ID']\n",
        "df.drop(columns=['Store ID'], inplace=True)"
      ],
      "metadata": {
        "id": "N5KBxMtjYFIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "E8_y18RQ9F4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column_name in [\"Store_Area\", \"Items_Available\", \"Daily_Customer_Count\" ,\"Store_Sales\"]:\n",
        "\n",
        "    # Compute statistics\n",
        "    mean_value = df[column_name].mean()\n",
        "\n",
        "    # Create a histogram trace\n",
        "    hist_trace = go.Histogram(\n",
        "        x=df[column_name],\n",
        "        histnorm='probability density',\n",
        "        name=\"Histogram\",\n",
        "        marker=dict(\n",
        "            color='blue',\n",
        "            line=dict(\n",
        "                color='black',\n",
        "                width=1\n",
        "            )\n",
        "        ),\n",
        "        opacity=0.7\n",
        "    )\n",
        "\n",
        "    # Create a KDE trace\n",
        "    kde_x_values = np.linspace(df[column_name].min(), df[column_name].max(), 200)\n",
        "    kde_y_values = stats.gaussian_kde(df[column_name].values)(kde_x_values)\n",
        "    kde_trace = go.Scatter(\n",
        "        x=kde_x_values,\n",
        "        y=kde_y_values,\n",
        "        mode='lines',\n",
        "        name=\"KDE\",\n",
        "        line=dict(\n",
        "            color='black',\n",
        "            width=1.5\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Create a vertical line trace for the mean\n",
        "    mean_trace = go.Scatter(\n",
        "        x=[mean_value, mean_value],\n",
        "        y=[0, max(kde_y_values)],\n",
        "        mode='lines',\n",
        "        name=\"Mean\",\n",
        "        line=dict(\n",
        "            color='red',\n",
        "            width=1,\n",
        "            dash='dash'\n",
        "        ),\n",
        "        hovertemplate=f\"Mean (Î¼): {mean_value:.2f}<extra></extra>\"\n",
        "    )\n",
        "\n",
        "    # Create a figure and add traces\n",
        "    fig = go.Figure([hist_trace, kde_trace, mean_trace])\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title=f\"{column_name} Distribution\",\n",
        "        xaxis_title=\"Score\",\n",
        "        yaxis_title=\"Density\",\n",
        "        bargap=0.01,  # gap between bars of histogram\n",
        "        bargroupgap=0.1  # gap between bars of different groups\n",
        "    )\n",
        "\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "KmvX6yRS9JAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column_name in [\"Store_Area\", \"Items_Available\", \"Daily_Customer_Count\"]:\n",
        "    # Create a box trace\n",
        "    box_trace = go.Box(\n",
        "        y=df[column_name],\n",
        "        name=column_name,\n",
        "        marker_color='blue'\n",
        "    )\n",
        "\n",
        "    # Create a figure and add trace\n",
        "    fig = go.Figure(box_trace)\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title=f\"{column_name} Box Plot\",\n",
        "        yaxis_title=column_name\n",
        "    )\n",
        "\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "ke9SGeLpA1aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = df.corr()\n",
        "\n",
        "# generate a heatmap\n",
        "fig = ff.create_annotated_heatmap(\n",
        "    z=correlation_matrix.values,\n",
        "    x=list(correlation_matrix.columns),\n",
        "    y=list(correlation_matrix.index),\n",
        "    annotation_text=correlation_matrix.round(2).values,\n",
        "    showscale=True,\n",
        "    colorscale=\"Viridis\"\n",
        ")\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Correlation Matrix',\n",
        "    xaxis=dict(title='Variable', side='bottom'),\n",
        "    yaxis=dict(title='Variable'),\n",
        "    width=800,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "1Ir_GPRP5sFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing and Machine Learning"
      ],
      "metadata": {
        "id": "TD13_zR87TF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the columns to be used for LOF analysis\n",
        "columns = [\"Store_Area\", \"Items_Available\", \"Daily_Customer_Count\"]\n",
        "\n",
        "# Create a subset DataFrame with the selected columns\n",
        "subset_df = df[columns]\n",
        "\n",
        "# Create an instance of the LocalOutlierFactor model\n",
        "lof = LocalOutlierFactor(n_neighbors=5)\n",
        "\n",
        "\n",
        "outlier_scores = lof.fit_predict(subset_df)\n",
        "\n",
        "# Create a mask to identify the outliers\n",
        "outlier_mask = outlier_scores == -1\n",
        "\n",
        "# Get the outliers from the original DataFrame\n",
        "outliers = df[outlier_mask]\n",
        "\n",
        "print(\"Outliers:\")\n",
        "print(outliers)\n"
      ],
      "metadata": {
        "id": "ZHsWOM-XB7-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the outliers from the original DataFrame\n",
        "df_no_outliers = df.drop(outliers.index)\n",
        "df_no_outliers.head()\n"
      ],
      "metadata": {
        "id": "Xbi8g3CMX5BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_no_outliers.info()"
      ],
      "metadata": {
        "id": "g-ieN-5-_5U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a scaler object\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the features and transform\n",
        "scaled_data = scaler.fit_transform(df_no_outliers)\n",
        "\n",
        "df_scaled = pd.DataFrame(scaled_data, columns=df.columns)\n",
        "df_scaled.head()"
      ],
      "metadata": {
        "id": "mjjOtGYzzKrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Store_Sales' is our target/dependent variable\n",
        "X = df_scaled.drop('Store_Sales', axis=1)\n",
        "y = df_scaled['Store_Sales']"
      ],
      "metadata": {
        "id": "wewZifMLSVvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the scaled data into a training set and a test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "hvP-8Vz0TGGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "fo28RVUqPJSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LinearRegression()\n",
        "\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "lr_pred =lr_model.predict(X_test)\n",
        "\n",
        "lr_mse = mean_squared_error(y_test, lr_pred)\n",
        "lr_mae = mean_absolute_error(y_test, lr_pred)\n",
        "\n",
        "score_lr = lr_model.score(X_train, y_train)\n",
        "r2_lr = r2_score(y_test, lr_pred)\n",
        "\n",
        "\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print('Linear Regression')\n",
        "print(\"MSE: %.2f\" % lr_mse)\n",
        "print(\"MAE: %.2f\" % lr_mae)\n",
        "print(\"Training score: \", score_lr)\n",
        "print(\"R2_score : %.2f\" % r2_lr)"
      ],
      "metadata": {
        "id": "RmhWWCtyPP2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Network"
      ],
      "metadata": {
        "id": "Num1nuYz7hJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, epochs=1500, batch_size=32, verbose=2)\n",
        "\n",
        "# Predict the 'Store_Sales' for the test set\n",
        "nn_predictions = model.predict(X_test)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "mse_nn = mean_squared_error(y_test, nn_predictions)\n",
        "mae_nn  = mean_absolute_error(y_test, nn_predictions)\n",
        "score_nn  = model.evaluate(X_train, y_train)\n",
        "r2_nn  = r2_score(y_test, nn_predictions)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print('Neural Network')\n",
        "print(\"MSE: %.2f\" % mse_nn )\n",
        "print(\"MAE: %.2f\" % mae_nn )\n",
        "print(\"Training loss: %.2f\" % score_nn )\n",
        "print(\"R2_score : %.2f\" % r2_nn)\n"
      ],
      "metadata": {
        "id": "JaPgQAKSUAQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decision Tree Regressor"
      ],
      "metadata": {
        "id": "UQPAkB4p7oyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "dt_model = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the 'Store_Sales' for the test set\n",
        "dt_predictions = dt_model.predict(X_test)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "mse_dt = mean_squared_error(y_test, dt_predictions)\n",
        "mae_dt = mean_absolute_error(y_test, dt_predictions)\n",
        "score_dt = dt_model.score(X_train, y_train)\n",
        "\n",
        "# Compute R-squared score\n",
        "r2_dt = r2_score(y_test, dt_predictions)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print('Decision Tree')\n",
        "print(\"MSE: %.2f\" % mse_dt)\n",
        "print(\"MAE: %.2f\" % mae_dt)\n",
        "print(\"Training score: %.2f\" % score_dt)\n",
        "print(\"R2_score : %.2f\" % r2_dt)\n"
      ],
      "metadata": {
        "id": "fpEmI_TFUP7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparison"
      ],
      "metadata": {
        "id": "BCtJOcKo7nGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the models and their respective evaluation metrics\n",
        "models = ['Linear Regression', 'Neural Network','Decision Tree' ]\n",
        "mse = [lr_mse, mse_nn, mse_dt]\n",
        "mae = [lr_mae, mae_nn, mae_dt]\n",
        "r2 = [r2_lr, r2_nn, r2_dt]\n",
        "\n",
        "# Create bar traces for each metric\n",
        "trace_mse = go.Bar(x=models, y=mse, name='MSE')\n",
        "trace_mae = go.Bar(x=models, y=mae, name='MAE')\n",
        "trace_r2 = go.Bar(x=models, y=r2, name='R2 Score')\n",
        "\n",
        "# Create a layout for the plot\n",
        "layout = go.Layout(\n",
        "    title='Comparison of Evaluation Metrics',\n",
        "    xaxis_title='Models',\n",
        "    yaxis_title='Metric Value'\n",
        ")\n",
        "\n",
        "# Create a figure and add the traces to it\n",
        "fig = go.Figure(data=[trace_mse,trace_mae, trace_r2], layout=layout)\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "qmuXUehANFAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Mining"
      ],
      "metadata": {
        "id": "6fgh9IGbbPjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_avgs = df.copy()\n",
        "df_avgs.head()"
      ],
      "metadata": {
        "id": "h0SmpeelbR9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PrOpr20M_Rmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avgs['ratio_items/cutomers'] = df_avgs['Items_Available']/df_avgs['Daily_Customer_Count']\n",
        "df_avgs['ratio_size/customers'] = df_avgs['Store_Area']/df_avgs['Daily_Customer_Count']\n",
        "df_avgs['ratio_size/items']     = df_avgs['Store_Area']/df_avgs['Items_Available']\n",
        "df_avgs['target_sales'] = df['Store_Sales']\n",
        "\n",
        "df_avgs.head()\n"
      ],
      "metadata": {
        "id": "8oGWfMfqbdy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avgs.drop(['Store_Area','Items_Available','Daily_Customer_Count','Store_Sales'],axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "SFvA0Ko1ekQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avgs.head()"
      ],
      "metadata": {
        "id": "IYxhNsgKemwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering Data"
      ],
      "metadata": {
        "id": "QdGdoi7HT9PT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the optimal number of clusters using the KElbowVisualizer\n",
        "\n",
        "x= df_avgs.drop('target_sales',axis= 1)\n",
        "kmeans_model = KMeans(n_init=10)\n",
        "visualizer = KElbowVisualizer(kmeans_model, k=(2, 10),n_init =10)  # Try different values of k\n",
        "visualizer.fit(x)\n",
        "visualizer.show()\n"
      ],
      "metadata": {
        "id": "n3PGNN8YUj_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans_model = KMeans(n_clusters=4,n_init=10, random_state=42)\n",
        "x['Cluster'] = kmeans_model.fit_predict(x)\n",
        "x.head()"
      ],
      "metadata": {
        "id": "qaKPrz2nZgPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df_avgs['target_sales']\n",
        "\n",
        "sales_join = x.join(y)\n",
        "sales_join.columns"
      ],
      "metadata": {
        "id": "Lx8mG0kfgnqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_join.head()"
      ],
      "metadata": {
        "id": "T-qux1VuPx2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_x = sales_join[['Cluster','target_sales']]\n",
        "\n",
        "\n",
        "kmeans_model = KMeans(n_init=10)\n",
        "visualizer = KElbowVisualizer(kmeans_model, k=(2, 10),n_init =10)  # Try different values of k\n",
        "visualizer.fit(sales_x)\n",
        "visualizer.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Jr0iHSNBnaAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans_model = KMeans(n_clusters=4,n_init=10, random_state=42)\n",
        "x['Target_Groups'] = kmeans_model.fit_predict(sales_x)\n",
        "x.head()"
      ],
      "metadata": {
        "id": "y6Sc9osZpFRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.concat([x, y], axis=1)\n",
        "combined_df.head()"
      ],
      "metadata": {
        "id": "Jwe82b0lAB5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the columns you want to scale\n",
        "columns_to_scale = ['ratio_items/cutomers', 'ratio_size/customers', 'ratio_size/items', 'target_sales']\n",
        "\n",
        "# Extract the columns you want to scale into a separate DataFrame\n",
        "X = combined_df[columns_to_scale]\n",
        "\n",
        "# Instantiate the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the selected columns\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Replace the original columns in the DataFrame with the scaled values\n",
        "combined_df[columns_to_scale] = X_scaled\n",
        "\n",
        "\n",
        "x= combined_df.drop('target_sales',axis= 1)\n",
        "y = combined_df['target_sales']"
      ],
      "metadata": {
        "id": "je1IPWynAguS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.head()"
      ],
      "metadata": {
        "id": "lM-eCnPmRIVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now Doing the Models Prediction on the clustered Data"
      ],
      "metadata": {
        "id": "JKZdWCqKaW0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second Linear Regression"
      ],
      "metadata": {
        "id": "t8EM0U4FrKCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)"
      ],
      "metadata": {
        "id": "HT_AtIOTpgbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_lr_model = LinearRegression()\n",
        "new_lr_model.fit(X_train, y_train)\n",
        "new_lr_pred =new_lr_model.predict(X_test)\n",
        "\n",
        "\n",
        "new_lr_mse = mean_squared_error(y_test, new_lr_pred)\n",
        "new_lr_mae = mean_absolute_error(y_test, new_lr_pred)\n",
        "\n",
        "new_score_lr = new_lr_model.score(X_train, y_train)\n",
        "new_r2_lr = r2_score(y_test, new_lr_pred)\n",
        "\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print('Linear Regression')\n",
        "print(\"MSE: %.2f\" % new_lr_mse)\n",
        "print(\"MAE: %.2f\" % new_lr_mae)\n",
        "print(\"Training score: \", new_score_lr)\n",
        "print(\"R2_score : %.2f\" % new_r2_lr)"
      ],
      "metadata": {
        "id": "t1k_GvYGqQd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtr = DecisionTreeRegressor()\n",
        "dtr.fit(X_train, y_train)\n",
        "dtr_pred =dtr.predict(X_test)\n",
        "\n",
        "new_mse_dt = mean_squared_error(y_test, dtr_pred)\n",
        "new_mae_dt = mean_absolute_error(y_test, dtr_pred)\n",
        "\n",
        "new_score_dt = dtr.score(X_train, y_train)\n",
        "new_r2_dt =r2_score(y_test,  dtr_pred)\n",
        "\n",
        "print('DecisionTree Regressor')\n",
        "print(\"MSE: %.2f\" % new_mse_dt)\n",
        "print(\"MAE: %.2f\" % (new_mae_dt))\n",
        "print(\"Training score: \", new_score_dt)\n",
        "print(\"R2_score : %.2f\"%(new_r2_dt))"
      ],
      "metadata": {
        "id": "AmD6E4KWrHAN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}